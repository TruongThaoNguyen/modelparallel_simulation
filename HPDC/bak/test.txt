#######################################################
-net ../HPDC/ALEXNET_ImageNet_prof.net1 -plat ABCI.plat -goal 1 --paratype ['o', 'd']
--cmaxB 262144.0 --cmaxp 2048.0 --cBon 512.0
====================================
Read platform from  ABCI.plat
====================================
FILE:  ABCI.plat
MEM_PER_NODE:  16000000000.0
NODE_SPEED:  7.8e+12
BANDWIDTH:  12500000000.0
LATENCY:  5e-07
MAX_NODE:  4096.0
====================================
Read dataset and DNN from  ../HPDC/ALEXNET_ImageNet_prof.net1
====================================
DATASET:  ImageNet
DATASET SIZE:  1280000.0
SAMPLE SIZE: 3x226x226 153228
====================================
Model:  AlexNet
LAYER	 x[C,W,H] 	 w[C,F,K,K] 	 y[F,W,H] 	 TComp
0 CONV1 	[3, 226, 226] = 153228 	[3, 96, 11, 11] = 34848 	[96, 54, 54] = 279936 	0.00107109375
1 RELU 	[96, 54, 54] = 279936 	[96, 96, 0, 0] = 0 	[96, 54, 54] = 279936 	0.0
2 MPOOL 	[96, 54, 54] = 279936 	[0, 0, 3, 3] = 0 	[96, 27, 27] = 69984 	0.0
3 CONV2 	[96, 27, 27] = 69984 	[96, 256, 5, 5] = 614400 	[256, 27, 27] = 186624 	0.0
4 RELU 	[256, 27, 27] = 186624 	[256, 256, 0, 0] = 0 	[256, 27, 27] = 186624 	0.0
5 MPOOL 	[256, 27, 27] = 186624 	[0, 0, 3, 3] = 0 	[256, 13, 13] = 43264 	0.0
6 CONV3 	[256, 13, 13] = 43264 	[256, 384, 3, 3] = 884736 	[384, 13, 13] = 64896 	0.0
7 RELU 	[384, 13, 13] = 64896 	[384, 384, 0, 0] = 0 	[384, 13, 13] = 64896 	0.0
8 CONV4 	[384, 13, 13] = 64896 	[384, 384, 3, 3] = 1327104 	[384, 13, 13] = 64896 	0.0
9 RELU 	[384, 13, 13] = 64896 	[384, 384, 0, 0] = 0 	[384, 13, 13] = 64896 	0.0
10 CONV5 	[384, 13, 13] = 64896 	[384, 256, 3, 3] = 884736 	[256, 13, 13] = 43264 	0.0
11 RELU 	[256, 13, 13] = 43264 	[256, 256, 0, 0] = 0 	[256, 13, 13] = 43264 	0.0
12 MPOOL 	[256, 13, 13] = 43264 	[0, 0, 3, 3] = 0 	[256, 6, 6] = 9216 	0.0
13 FC6 	[256, 6, 6] = 9216 	[256, 4096, 6, 6] = 37748736 	[4096, 1, 1] = 4096 	0.0
14 RELU 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	0.0
15 DROPOUT 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	0.0
16 FC7 	[4096, 1, 1] = 4096 	[4096, 4096, 1, 1] = 16777216 	[4096, 1, 1] = 4096 	0.0
17 RELU 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	0.0
18 DROPOUT 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	0.0
19 FC8 	[4096, 1, 1] = 4096 	[4096, 1000, 1, 1] = 4096000 	[1000, 1, 1] = 1000 	0.0
Model with 20 layers
Total |x|: 931692 items
Total |y|: 779464 items
Total |w|: 62367776 items
Total comp: 0.00107109375 sec
Max comp: 0.00107109375 sec ==>933.625091174samples for 100% GPU ultilization
Max |y|: 279936 items
****
global value g GOAL 1
MAX_MINIBATCH 262144.0
MAX_RANK 2048.0
FIX_MIRCO_BATCH 512.0
NODE_SPEED 7.8e+12
MEM_PER_NODE 16000000000.0
ITEM_PER_NODE 4000000000.0
BW_FACTOR 8e-11
LATENCY_FACTOR 5e-07
TOTAL_SAMPLE 1280000.0
GPU_PER_NODE 4

{'maxOut': 279936, 'totalOut': 779464, 'minFilter': 96, 'minChannel': 3, 'totalIn': 931692, 'totalComp': 0.00107109375, 'totalWeight': 62367776, 'minW': 1}
==========SINGLE-NODE===============
maxSamplePerNode: 2264.70552539
Use FIX_MIRCO_BATCH set by user for miniBatch:  512.0
==========DATA PARALLELISM==========
maxSamplePerNode: 2264.70552539
Use FIX_MIRCO_BATCH set by user,  512.0
==================SUMMARY==================
name		B	p	Mem (bytes)	Tcomp (s)	Tcomm(s)	Time(s)	Cost(min*Node)
single		512.0	1	7507837184.0	1371.0	0	1371.0	23.0
data		1024.0	2.0	7507837184.0	685.5	6.2592776	691.7592776	24.0
data		2048.0	4.0	7507837184.0	342.75	4.7113332	347.4613332	24.0
data		4096.0	8.0	7507837184.0	171.375	11.0646421973	182.439642197	32.0
data		8192.0	16.0	7507837184.0	85.6875	6.0178045992	91.7053045992	32.0
data		16384.0	32.0	7507837184.0	42.84375	3.20323204848	46.0469820485	32.0
data		32768.0	64.0	7507837184.0	21.421875	1.7244303552	23.1463053552	64.0
data		65536.0	128.0	7507837184.0	10.7109375	0.9469599552	11.6578974552	128.0
data		131072.0	256.0	7507837184.0	5.35546875	0.555592572	5.911061322	256.0
data		262144.0	512.0	7507837184.0	2.677734375	0.3574948846	3.0352292596	512.0
#######################################################
-net ../HPDC/ALEXNET_ImageNet_prof.net -plat ABCI.plat -goal 1 --paratype ['o', 'd']
--cmaxB 262144.0 --cmaxp 2048.0 --cBon 512.0
====================================
Read platform from  ABCI.plat
====================================
FILE:  ABCI.plat
MEM_PER_NODE:  16000000000.0
NODE_SPEED:  7.8e+12
BANDWIDTH:  12500000000.0
LATENCY:  5e-07
MAX_NODE:  4096.0
====================================
Read dataset and DNN from  ../HPDC/ALEXNET_ImageNet_prof.net
====================================
DATASET:  ImageNet
DATASET SIZE:  1280000.0
SAMPLE SIZE: 3x226x226 153228
====================================
Model:  AlexNet
LAYER	 x[C,W,H] 	 w[C,F,K,K] 	 y[F,W,H] 	 TComp
0 CONV1 	[3, 226, 226] = 153228 	[3, 96, 11, 11] = 34848 	[96, 54, 54] = 279936 	0.00120901
1 RELU 	[96, 54, 54] = 279936 	[96, 96, 0, 0] = 0 	[96, 54, 54] = 279936 	5.926e-05
2 MPOOL 	[96, 54, 54] = 279936 	[0, 0, 3, 3] = 0 	[96, 27, 27] = 69984 	4.387e-05
3 CONV2 	[96, 27, 27] = 69984 	[96, 256, 5, 5] = 614400 	[256, 27, 27] = 186624 	0.00025005
4 RELU 	[256, 27, 27] = 186624 	[256, 256, 0, 0] = 0 	[256, 27, 27] = 186624 	4.948e-05
5 MPOOL 	[256, 27, 27] = 186624 	[0, 0, 3, 3] = 0 	[256, 13, 13] = 43264 	4.021e-05
6 CONV3 	[256, 13, 13] = 43264 	[256, 384, 3, 3] = 884736 	[384, 13, 13] = 64896 	0.00020321
7 RELU 	[384, 13, 13] = 64896 	[384, 384, 0, 0] = 0 	[384, 13, 13] = 64896 	4.715e-05
8 CONV4 	[384, 13, 13] = 64896 	[384, 384, 3, 3] = 1327104 	[384, 13, 13] = 64896 	0.00047687
9 RELU 	[384, 13, 13] = 64896 	[384, 384, 0, 0] = 0 	[384, 13, 13] = 64896 	4.556e-05
10 CONV5 	[384, 13, 13] = 64896 	[384, 256, 3, 3] = 884736 	[256, 13, 13] = 43264 	0.00027486
11 RELU 	[256, 13, 13] = 43264 	[256, 256, 0, 0] = 0 	[256, 13, 13] = 43264 	4.383e-05
12 MPOOL 	[256, 13, 13] = 43264 	[0, 0, 3, 3] = 0 	[256, 6, 6] = 9216 	3.837e-05
13 FC6 	[256, 6, 6] = 9216 	[256, 4096, 6, 6] = 37748736 	[4096, 1, 1] = 4096 	0.00059829
14 RELU 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	4.257e-05
15 DROPOUT 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	8.593e-05
16 FC7 	[4096, 1, 1] = 4096 	[4096, 4096, 1, 1] = 16777216 	[4096, 1, 1] = 4096 	0.00015191
17 RELU 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	4.028e-05
18 DROPOUT 	[4096, 1, 1] = 4096 	[4096, 4096, 0, 0] = 0 	[4096, 1, 1] = 4096 	7.762e-05
19 FC8 	[4096, 1, 1] = 4096 	[4096, 1000, 1, 1] = 4096000 	[1000, 1, 1] = 1000 	9.346e-05
Model with 20 layers
Total |x|: 931692 items
Total |y|: 779464 items
Total |w|: 62367776 items
Total comp: 0.00387179 sec
Max comp: 0.00120901 sec ==>258.278470682samples for 100% GPU ultilization
Max |y|: 279936 items
****
global value g GOAL 1
MAX_MINIBATCH 262144.0
MAX_RANK 2048.0
FIX_MIRCO_BATCH 512.0
NODE_SPEED 7.8e+12
MEM_PER_NODE 16000000000.0
ITEM_PER_NODE 4000000000.0
BW_FACTOR 8e-11
LATENCY_FACTOR 5e-07
TOTAL_SAMPLE 1280000.0
GPU_PER_NODE 4

{'maxOut': 279936, 'totalOut': 779464, 'minFilter': 96, 'minChannel': 3, 'totalIn': 931692, 'totalComp': 0.00387179, 'totalWeight': 62367776, 'minW': 1}
==========SINGLE-NODE===============
maxSamplePerNode: 2264.70552539
Use FIX_MIRCO_BATCH set by user for miniBatch:  512.0
==========DATA PARALLELISM==========
maxSamplePerNode: 2264.70552539
Use FIX_MIRCO_BATCH set by user,  512.0
==================SUMMARY==================
name		B	p	Mem (bytes)	Tcomp (s)	Tcomm(s)	Time(s)	Cost(min*Node)
single		512.0	1	7507837184.0	4955.8912	0	4955.8912	83.0
data		1024.0	2.0	7507837184.0	2477.9456	6.2592776	2484.2048776	84.0
data		2048.0	4.0	7507837184.0	1238.9728	4.7113332	1243.6841332	84.0
data		4096.0	8.0	7507837184.0	619.4864	11.0646421973	630.551042197	88.0
data		8192.0	16.0	7507837184.0	309.7432	6.0178045992	315.761004599	96.0
data		16384.0	32.0	7507837184.0	154.8716	3.20323204848	158.074832048	96.0
data		32768.0	64.0	7507837184.0	77.4358	1.7244303552	79.1602303552	128.0
data		65536.0	128.0	7507837184.0	38.7179	0.9469599552	39.6648599552	128.0
data		131072.0	256.0	7507837184.0	19.35895	0.555592572	19.914542572	256.0
data		262144.0	512.0	7507837184.0	9.679475	0.3574948846	10.0369698846	512.0
#######################################################
-net ../HPDC/RESNET50_ImageNet.net1 -plat ABCI.plat -goal 1 --paratype ['o', 'd', 's']
--cmaxB 262144.0 --cmaxp 2048.0 --cBon 64.0
====================================
Read platform from  ABCI.plat
====================================
FILE:  ABCI.plat
MEM_PER_NODE:  16000000000.0
NODE_SPEED:  7.8e+12
BANDWIDTH:  12500000000.0
LATENCY:  5e-07
MAX_NODE:  4096.0
====================================
Read dataset and DNN from  ../HPDC/RESNET50_ImageNet.net1
# First block group
#
#
# Second block group
#
#
#
# Third block group
#
#
#
#
#
# Forth block group
#
#
# Fully connected
====================================
DATASET:  ImageNet
DATASET SIZE:  1280000.0
SAMPLE SIZE: 3x226x226 153228
====================================
Model:  ResNet50
LAYER	 x[C,W,H] 	 w[C,F,K,K] 	 y[F,W,H] 	 TComp
0 CONV_1 	[3, 226, 226] = 153228 	[3, 64, 7, 7] = 9408 	[64, 113, 113] = 817216 	0.002990625
1 BNORM 	[64, 113, 113] = 817216 	[64, 64, 0, 0] = 0 	[64, 113, 113] = 817216 	0.0
2 RELU 	[64, 113, 113] = 817216 	[64, 64, 0, 0] = 0 	[64, 113, 113] = 817216 	0.0
3 MPOOL 	[64, 113, 113] = 817216 	[0, 0, 3, 3] = 0 	[64, 56, 56] = 200704 	0.0
4 CONV_2a1 	[64, 56, 56] = 200704 	[64, 64, 1, 1] = 4096 	[64, 56, 56] = 200704 	0.0
5 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
6 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
7 CONV_2a2 	[64, 56, 56] = 200704 	[64, 64, 3, 3] = 36864 	[64, 56, 56] = 200704 	0.0
8 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
9 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
10 CONV_2a3 	[64, 56, 56] = 200704 	[64, 256, 1, 1] = 16384 	[256, 56, 56] = 802816 	0.0
11 BNORM 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
12 ADD 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
13 RELU 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
14 CONV_2b1 	[256, 56, 56] = 802816 	[256, 64, 1, 1] = 16384 	[64, 56, 56] = 200704 	0.0
15 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
16 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
17 CONV_2b2 	[64, 56, 56] = 200704 	[64, 64, 3, 3] = 36864 	[64, 56, 56] = 200704 	0.0
18 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
19 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
20 CONV_2b3 	[64, 56, 56] = 200704 	[64, 256, 1, 1] = 16384 	[256, 56, 56] = 802816 	0.0
21 BNORM 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
22 ADD 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
23 RELU 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
24 CONV_2c1 	[256, 56, 56] = 802816 	[256, 64, 1, 1] = 16384 	[64, 56, 56] = 200704 	0.0
25 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
26 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
27 CONV_2c2 	[64, 56, 56] = 200704 	[64, 64, 3, 3] = 36864 	[64, 56, 56] = 200704 	0.0
28 BNORM 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
29 RELU 	[64, 56, 56] = 200704 	[64, 64, 0, 0] = 0 	[64, 56, 56] = 200704 	0.0
30 CONV_2c3 	[64, 56, 56] = 200704 	[64, 256, 1, 1] = 16384 	[256, 56, 56] = 802816 	0.0
31 BNORM 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
32 ADD 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
33 RELU 	[256, 56, 56] = 802816 	[256, 256, 0, 0] = 0 	[256, 56, 56] = 802816 	0.0
34 CONV_3a1 	[256, 56, 56] = 802816 	[256, 128, 1, 1] = 32768 	[128, 28, 28] = 100352 	0.0
35 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
36 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
37 CONV_3a2 	[128, 28, 28] = 100352 	[128, 128, 3, 3] = 147456 	[128, 28, 28] = 100352 	0.0
38 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
39 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
40 CONV_3a3 	[128, 28, 28] = 100352 	[128, 512, 1, 1] = 65536 	[512, 28, 28] = 401408 	0.0
41 BNORM 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
42 ADD 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
43 RELU 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
44 CONV_3b1 	[512, 28, 28] = 401408 	[512, 128, 1, 1] = 65536 	[128, 28, 28] = 100352 	0.0
45 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
46 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
47 CONV_3b2 	[128, 28, 28] = 100352 	[128, 128, 3, 3] = 147456 	[128, 28, 28] = 100352 	0.0
48 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
49 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
50 CONV_3b3 	[128, 28, 28] = 100352 	[128, 512, 1, 1] = 65536 	[512, 28, 28] = 401408 	0.0
51 BNORM 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
52 ADD 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
53 RELU 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
54 CONV_3c1 	[512, 28, 28] = 401408 	[512, 128, 1, 1] = 65536 	[128, 28, 28] = 100352 	0.0
55 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
56 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
57 CONV_3c2 	[128, 28, 28] = 100352 	[128, 128, 3, 3] = 147456 	[128, 28, 28] = 100352 	0.0
58 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
59 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
60 CONV_3c3 	[128, 28, 28] = 100352 	[128, 512, 1, 1] = 65536 	[512, 28, 28] = 401408 	0.0
61 BNORM 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
62 ADD 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
63 RELU 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
64 CONV_3d1 	[512, 28, 28] = 401408 	[512, 128, 1, 1] = 65536 	[128, 28, 28] = 100352 	0.0
65 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
66 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
67 CONV_3d2 	[128, 28, 28] = 100352 	[128, 128, 3, 3] = 147456 	[128, 28, 28] = 100352 	0.0
68 BNORM 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
69 RELU 	[128, 28, 28] = 100352 	[128, 128, 0, 0] = 0 	[128, 28, 28] = 100352 	0.0
70 CONV_3d3 	[128, 28, 28] = 100352 	[128, 512, 1, 1] = 65536 	[512, 28, 28] = 401408 	0.0
71 BNORM 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
72 ADD 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
73 RELU 	[512, 28, 28] = 401408 	[512, 512, 0, 0] = 0 	[512, 28, 28] = 401408 	0.0
74 CONV_4a1 	[512, 28, 28] = 401408 	[512, 256, 1, 1] = 131072 	[256, 14, 14] = 50176 	0.0
75 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
76 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
77 CONV_4a2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
78 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
79 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
80 CONV_4a3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
81 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
82 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
83 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
84 CONV_4b1 	[1024, 14, 14] = 200704 	[1024, 256, 1, 1] = 262144 	[256, 14, 14] = 50176 	0.0
85 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
86 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
87 CONV_4b2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
88 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
89 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
90 CONV_4b3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
91 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
92 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
93 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
94 CONV_4c1 	[1024, 14, 14] = 200704 	[1024, 256, 1, 1] = 262144 	[256, 14, 14] = 50176 	0.0
95 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
96 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
97 CONV_4c2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
98 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
99 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
100 CONV_4c3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
101 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
102 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
103 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
104 CONV_4d1 	[1024, 14, 14] = 200704 	[1024, 256, 1, 1] = 262144 	[256, 14, 14] = 50176 	0.0
105 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
106 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
107 CONV_4d2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
108 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
109 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
110 CONV_4d3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
111 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
112 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
113 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
114 CONV_4e1 	[1024, 14, 14] = 200704 	[1024, 256, 1, 1] = 262144 	[256, 14, 14] = 50176 	0.0
115 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
116 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
117 CONV_4e2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
118 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
119 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
120 CONV_4e3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
121 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
122 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
123 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
124 CONV_4f1 	[1024, 14, 14] = 200704 	[1024, 256, 1, 1] = 262144 	[256, 14, 14] = 50176 	0.0
125 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
126 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
127 CONV_4f2 	[256, 14, 14] = 50176 	[256, 256, 3, 3] = 589824 	[256, 14, 14] = 50176 	0.0
128 BNORM 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
129 RELU 	[256, 14, 14] = 50176 	[256, 256, 0, 0] = 0 	[256, 14, 14] = 50176 	0.0
130 CONV_4f3 	[256, 14, 14] = 50176 	[256, 1024, 1, 1] = 262144 	[1024, 14, 14] = 200704 	0.0
131 BNORM 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
132 ADD 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
133 RELU 	[1024, 14, 14] = 200704 	[1024, 1024, 0, 0] = 0 	[1024, 14, 14] = 200704 	0.0
134 CONV_5a1 	[1024, 14, 14] = 200704 	[1024, 512, 1, 1] = 524288 	[512, 7, 7] = 25088 	0.0
135 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
136 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
137 CONV_5a2 	[512, 7, 7] = 25088 	[512, 512, 3, 3] = 2359296 	[512, 7, 7] = 25088 	0.0
138 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
139 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
140 CONV_5a3 	[512, 7, 7] = 25088 	[512, 2048, 1, 1] = 1048576 	[2048, 7, 7] = 100352 	0.0
141 BNORM 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
142 ADD 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
143 RELU 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
144 CONV_5b1 	[2048, 7, 7] = 100352 	[2048, 512, 1, 1] = 1048576 	[512, 7, 7] = 25088 	0.0
145 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
146 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
147 CONV_5b2 	[512, 7, 7] = 25088 	[512, 512, 3, 3] = 2359296 	[512, 7, 7] = 25088 	0.0
148 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
149 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
150 CONV_5b3 	[512, 7, 7] = 25088 	[512, 2048, 1, 1] = 1048576 	[2048, 7, 7] = 100352 	0.0
151 BNORM 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
152 ADD 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
153 RELU 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
154 CONV_5c1 	[2048, 7, 7] = 100352 	[2048, 512, 1, 1] = 1048576 	[512, 7, 7] = 25088 	0.0
155 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
156 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
157 CONV_5c2 	[512, 7, 7] = 25088 	[512, 512, 3, 3] = 2359296 	[512, 7, 7] = 25088 	0.0
158 BNORM 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
159 RELU 	[512, 7, 7] = 25088 	[512, 512, 0, 0] = 0 	[512, 7, 7] = 25088 	0.0
160 CONV_5c3 	[512, 7, 7] = 25088 	[512, 2048, 1, 1] = 1048576 	[2048, 7, 7] = 100352 	0.0
161 BNORM 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
162 ADD 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
163 RELU 	[2048, 7, 7] = 100352 	[2048, 2048, 0, 0] = 0 	[2048, 7, 7] = 100352 	0.0
164 APOOL 	[2048, 7, 7] = 100352 	[0, 0, 7, 7] = 0 	[2048, 1, 1] = 2048 	0.0
165 FC6 	[2048, 1, 1] = 2048 	[2048, 1000, 1, 1] = 2048000 	[1000, 1, 1] = 1000 	0.0
Model with 166 layers
Total |x|: 14971596 items
Total |y|: 14819368 items
Total |w|: 22734016 items
Total comp: 0.002990625 sec
Max comp: 0.002990625 sec ==>334.378265413samples for 100% GPU ultilization
Max |y|: 817216 items
****
global value g GOAL 1
MAX_MINIBATCH 262144.0
MAX_RANK 2048.0
FIX_MIRCO_BATCH 64.0
NODE_SPEED 7.8e+12
MEM_PER_NODE 16000000000.0
ITEM_PER_NODE 4000000000.0
BW_FACTOR 8e-11
LATENCY_FACTOR 5e-07
TOTAL_SAMPLE 1280000.0
GPU_PER_NODE 4

{'maxOut': 817216, 'totalOut': 14819368, 'minFilter': 64, 'minChannel': 3, 'totalIn': 14971596, 'totalComp': 0.002990625, 'totalWeight': 22734016, 'minW': 1}
==========SINGLE-NODE===============
maxSamplePerNode: 132.742665461
Use FIX_MIRCO_BATCH set by user for miniBatch:  64.0
==========DATA PARALLELISM==========
maxSamplePerNode: 132.742665461
Use FIX_MIRCO_BATCH set by user,  64.0
==========SPATIAL PARALLELISM==========
max_rank 1
==================SUMMARY==================
name		B	p	Mem (bytes)	Tcomp (s)	Tcomm(s)	Time(s)	Cost(min*Node)
single		64.0	1	15434845696.0	3828.0	0	3828.0	64.0
data		128.0	2.0	15434845696.0	1914.0	18.3672128	1932.3672128	66.0
data		256.0	4.0	15434845696.0	957.0	13.9104096	970.9104096	68.0
data		512.0	8.0	15434845696.0	478.5	32.8884724	511.3884724	72.0
data		1024.0	16.0	15434845696.0	239.25	18.187137	257.437137	80.0
data		2048.0	32.0	15434845696.0	119.625	9.9839437	129.6089437	96.0
data		4096.0	64.0	15434845696.0	59.8125	5.67828639504	65.490786395	128.0
data		8192.0	128.0	15434845696.0	29.90625	3.48234794512	33.3885979451	128.0
data		16384.0	256.0	15434845696.0	14.953125	2.3931260808	17.3462510808	256.0
data		32768.0	512.0	15434845696.0	7.4765625	1.8473165088	9.3238790088	512.0
data		65536.0	1024.0	15434845696.0	3.73828125	1.5584128296	5.2966940796	1024.0
data		131072.0	2048.0	15434845696.0	1.869140625	1.4137478586	3.2828884836	2048.0
#######################################################
-net ../HPDC/VGG_ImageNet_prof.net -plat ABCI.plat -goal 1 --paratype ['o', 'd', 's']
--cmaxB 262144.0 --cmaxp 2048.0 --cBon 32.0
====================================
Read platform from  ABCI.plat
====================================
Read dataset and DNN from  ../HPDC/VGG_ImageNet_prof.net
==========SINGLE-NODE===============
maxSamplePerNode: 117.102356957
Use FIX_MIRCO_BATCH set by user for miniBatch:  32.0
==========DATA PARALLELISM==========
maxSamplePerNode: 117.102356957
Use FIX_MIRCO_BATCH set by user,  32.0
==========SPATIAL PARALLELISM==========
max_rank 8
maxSamplePerNode: 499.752769914
Use FIX_MIRCO_BATCH set by user,  32.0
2.0 0.00204435
maxSamplePerNode: 592.521248161
Use FIX_MIRCO_BATCH set by user,  32.0
4.0 0.001724275
maxSamplePerNode: 653.142233947
Use FIX_MIRCO_BATCH set by user,  32.0
8.0 0.0015642375
==================SUMMARY==================
name		B	p	Mem (bytes)	Tcomp (s)	Tcomm(s)	Time(s)	Cost(min*Node)
single		32.0	1	9360484864.0	9750.656	0	9750.656	163.0
data		64.0	2.0	9360484864.0	4875.328	272.0422528	5147.3702528	172.0
data		128.0	4.0	9360484864.0	2437.664	204.3016896	2641.9656896	180.0
data		256.0	8.0	9360484864.0	1218.832	477.5656424	1696.3976424	232.0
data		512.0	16.0	9360484864.0	609.416	256.975362	866.391362	240.0
data		1024.0	32.0	9360484864.0	304.708	133.9451162	438.6531162	256.0
data		2048.0	64.0	9360484864.0	152.354	69.2462169	221.6002169	256.0
data		4096.0	128.0	9360484864.0	76.177	36.172894827	112.349894827	256.0
data		8192.0	256.0	9360484864.0	38.0885	19.4755670232	57.5640670232	256.0
data		16384.0	512.0	9360484864.0	19.04425	11.0696545394	30.1139045394	512.0
data		32768.0	1024.0	9360484864.0	9.522125	6.8780742096	16.4001992096	1024.0
data		65536.0	2048.0	9360484864.0	4.7610625	4.7090391636	9.4701016636	2048.0
spatial		32.0	2.0	2295936512.0	2616.768	592.8250624	3209.5930624	108.0
spatial		32.0	4.0	1753781760.0	2207.072	869.0650368	3076.1370368	208.0
spatial		32.0	8.0	1537748480.0	2002.224	4011.424896	6013.648896	808.0
